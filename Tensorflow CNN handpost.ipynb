{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei Han Chen\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_data_directory = \"Dataset/Color\"\n",
    "annotation_url = 'Dataset/annotation.json'\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(annotation_url) as annotation:\n",
    "    annotation_data = json.load(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = [\n",
    "\t\t[100.,  100.,  100.], \n",
    "\t\t[100.,    0.,    0.],\n",
    "\t\t[150.,    0.,    0.],\n",
    "\t\t[200.,    0.,    0.],\n",
    "\t\t[255.,    0.,    0.],\n",
    "\t\t[100.,  100.,    0.],\n",
    "\t\t[150.,  150.,    0.],\n",
    "\t\t[200.,  200.,    0.],\n",
    "\t\t[255.,  255.,    0.],\n",
    "\t\t[  0.,  100.,   50.],\n",
    "\t\t[  0.,  150.,   75.],\n",
    "\t\t[  0.,  200.,  100.],\n",
    "\t\t[  0.,  255.,  125.],\n",
    "\t\t[  0.,   50.,  100.],\n",
    "\t\t[  0.,   75.,  150.],\n",
    "\t\t[  0.,  100.,  200.],\n",
    "\t\t[  0.,  125.,  255.],\n",
    "\t\t[100.,    0.,  100.],\n",
    "\t\t[150.,    0.,  150.],\n",
    "        [200.,    0.,  200.],\n",
    "        [255.,    0.,  255.]]\n",
    "\n",
    "colors = np.divide(np.array(colors), 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImageData(image, pos, resize_ratio_x, resize_ratio_y, name):\n",
    "    \n",
    "    newpos_x = pos[:,0] / resize_ratio_x\n",
    "    newpos_y = pos[:,1] / resize_ratio_y\n",
    "    \n",
    "    top_left_x = np.amin(newpos_x) - 2\n",
    "    top_left_y = np.amin(newpos_y) - 2\n",
    "    \n",
    "    width = np.amax(newpos_x) - top_left_x + 2\n",
    "    height = np.amax(newpos_y) - top_left_y + 2\n",
    "\n",
    "    return top_left_x, top_left_y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCropImageData(image, pos, resize_ratio_x, resize_ratio_y,  name):\n",
    "    \n",
    "    newpos_x = pos[:,0] / resize_ratio_x\n",
    "    newpos_y = pos[:,1] / resize_ratio_y\n",
    "    \n",
    "    top_left_x = np.amin(newpos_x) - 10\n",
    "    top_left_y = np.amin(newpos_y) - 10\n",
    "    \n",
    "    width = np.amax(newpos_x) - top_left_x + 20\n",
    "    height = np.amax(newpos_y) - top_left_y + 20\n",
    "\n",
    "\n",
    "    return int(top_left_x), int(top_left_y), int(width), int(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotImageData(image, pos, resize_ratio_x, resize_ratio_y, name):\n",
    "    plt.figure(figsize=(20,10))\n",
    "#     image = rgb2gray(image)\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    newpos_x = pos[:,0] / resize_ratio_x\n",
    "    newpos_y = pos[:,1] / resize_ratio_y\n",
    "    \n",
    "    top_left_x = np.amin(newpos_x) - 2\n",
    "    top_left_y = np.amin(newpos_y) - 2\n",
    "    \n",
    "    width = np.amax(newpos_x) - top_left_x + 2\n",
    "    height = np.amax(newpos_y) - top_left_y + 2\n",
    "\n",
    "    \n",
    "    rect = patches.Rectangle((top_left_x,top_left_y),width,height,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    \n",
    "    plt.gca().add_patch(rect)\n",
    "    \n",
    "    plt.scatter(x=newpos_x, y=newpos_y, c=colors, s=10, alpha=0.7)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_part_data(names, data_directory, annotation_data):\n",
    "\n",
    "    old_x = 1080\n",
    "    old_y = 1920\n",
    "    reshaped_x = 126\n",
    "    reshaped_y = 224\n",
    "    cropped_resize_x = 32\n",
    "    cropped_resize_y = 32\n",
    "    \n",
    "    allImages = np.empty((len(names), reshaped_x, reshaped_y, 3))\n",
    "    allCroppedImages = np.empty((len(names), cropped_resize_x, cropped_resize_y, 3))\n",
    "    allBoxs = np.empty((len(names), 4))\n",
    "    allLabels = []\n",
    "    \n",
    "    for i in range(len(names)):\n",
    "        name = names[i]\n",
    "        label = 1 if name[-1] == 'L' else 2\n",
    "        \n",
    "        # get default but resized images\n",
    "            \n",
    "#         image = imread(data_directory + \"/\" + name[:-2] + \".jpg\")\n",
    "        path = data_directory + \"/\" + name[:-2] + \".jpg\"\n",
    "        \n",
    "        image = tf.keras.preprocessing.image.load_img(path, target_size=(reshaped_x, reshaped_y))\n",
    "        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        \n",
    "        pos = np.array(annotation_data[name])\n",
    "\n",
    "        resize_ratio_x = old_x / reshaped_x\n",
    "        resize_ratio_y = old_y / reshaped_y\n",
    "                                                      \n",
    "#         resized_image = tf.image.resize_images(images=image,size=[reshaped_x, reshaped_y])\n",
    "                                                      \n",
    "#         resized_image = resize(image, (reshaped_x, reshaped_y, 3))\n",
    "        \n",
    "                                                      \n",
    "                                                      \n",
    "        top_x, top_y, width, height = getImageData(image, pos, \n",
    "                                        resize_ratio_x, resize_ratio_y, name)        \n",
    "        boundingBox = np.array([top_x, top_y, width, height])\n",
    "        \n",
    "        newLabel = np.array([label])\n",
    "        \n",
    "        allImages[i] = image\n",
    "        allBoxs[i] = boundingBox\n",
    "        \n",
    "        allLabels.append(newLabel) \n",
    "        \n",
    "\n",
    "        # get cropped images\n",
    "        \n",
    "        top_x, top_y, width, height = getCropImageData(image, pos, resize_ratio_x, resize_ratio_y,  name)    \n",
    "        \n",
    "        cropped_image = image[top_y: top_y + height, top_x: top_x + width, :]\n",
    "                \n",
    "        \n",
    "        \n",
    "        cropped_image = resize(cropped_image / 255, (cropped_resize_x, cropped_resize_y, 3)) * 255\n",
    "        \n",
    "        allCroppedImages[i] = cropped_image\n",
    "        \n",
    "    \n",
    "    print(allImages.shape)\n",
    "    print(allBoxs.shape)\n",
    "    \n",
    "    return allImages, allCroppedImages, np.concatenate(allLabels), allBoxs\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_directory, annotation_data):\n",
    "    names = list(annotation_data.keys())\n",
    "\n",
    "    print(\"Get train\")\n",
    "    train_data = np.array(names[:1000])\n",
    "    X_train, X_crop_train, Y_train_label, Y_train_box = load_part_data(train_data, data_directory, annotation_data)\n",
    "    \n",
    "    \n",
    "    print(\"Get valid\")\n",
    "    valid_data = np.array(names[2000:2500])\n",
    "    X_val, X_crop_val, Y_val_label, Y_val_box = load_part_data(valid_data, data_directory, annotation_data)\n",
    "    \n",
    "    print(\"Get test\")\n",
    "    test_data = np.array(names[3000:3500])\n",
    "    X_test, X_crop_test, Y_test_label, Y_test_box = load_part_data(test_data, data_directory, annotation_data)\n",
    "    \n",
    "    \n",
    "    return (X_train, X_crop_train, Y_train_label, Y_train_box, \n",
    "            X_val, X_crop_val, Y_val_label, Y_val_box, \n",
    "            X_test, X_crop_test, Y_test_label, Y_test_box)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei Han Chen\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 126, 224, 3)\n",
      "(1000, 4)\n",
      "Get valid\n",
      "(500, 126, 224, 3)\n",
      "(500, 4)\n",
      "Get test\n",
      "(500, 126, 224, 3)\n",
      "(500, 4)\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_crop_train, Y_train_label, Y_train_box, \n",
    " X_val, X_crop_val, Y_val_label, Y_val_box, \n",
    " X_test, X_crop_test, Y_test_label, Y_test_box) = load_data(image_data_directory, annotation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 126, 224, 3)\n",
      "(1000, 32, 32, 3)\n",
      "(1000,)\n",
      "(1000, 4)\n",
      "(500, 126, 224, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500,)\n",
      "(500, 4)\n",
      "(500, 126, 224, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500,)\n",
      "(500, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_crop_train.shape)\n",
    "print(Y_train_label.shape)\n",
    "print(Y_train_box.shape)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(X_crop_val.shape)\n",
    "print(Y_val_label.shape)\n",
    "print(Y_val_box.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_crop_test.shape)\n",
    "print(Y_test_label.shape)\n",
    "print(Y_test_box.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Model\n",
    "\n",
    "image data will have size N x W x H x C\n",
    "\n",
    "N = number of images\n",
    "\n",
    "W = width\n",
    "\n",
    "H = height\n",
    "\n",
    "C = RGB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1, output_type=tf.int32), Y_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         Y_label: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_model(X, y, is_training):\n",
    "    convW1 = tf.get_variable('convW1', [5,5,3,30])\n",
    "    convB1 = tf.get_variable('convB1', [30])\n",
    "    convW2 = tf.get_variable('convW2', [3,3,30,60])\n",
    "    convB2 = tf.get_variable('convB2', [60])\n",
    "    convW3 = tf.get_variable('convW3', [5,5,60, 120])\n",
    "    convB3 = tf.get_variable('convB3', [120]) \n",
    "    convW4 = tf.get_variable('convW4', [5,5,120, 100])\n",
    "    convB4 = tf.get_variable('convB4', [100]) \n",
    "    convW5 = tf.get_variable('convW5', [8,8, 100, 3])\n",
    "    convB5 = tf.get_variable('convB5', [3]) \n",
    "    \n",
    "    print(X.shape)\n",
    "    \n",
    "    a1 = tf.nn.conv2d(X, convW1, strides=[1,1,1,1], padding=\"SAME\") + convB1\n",
    "    \n",
    "    \n",
    "    h1_batched = tf.layers.batch_normalization(a1, center=True, scale=True, training=is_training)\n",
    "    \n",
    "    \n",
    "    h1 = tf.nn.elu(h1_batched)\n",
    "    h1_pooled = tf.nn.max_pool(h1, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    a2 = tf.nn.conv2d(h1_pooled, convW2, strides=[1,1,1,1], padding=\"SAME\") + convB2\n",
    "    h2_batched = tf.layers.batch_normalization(a2, center=True, scale=True, training=is_training)\n",
    "    h2 = tf.nn.elu(h2_batched)\n",
    "    h2_pooled = tf.nn.max_pool(h2, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    \n",
    "    a3 = tf.nn.conv2d(h2_pooled, convW3, strides=[1,1,1,1], padding=\"SAME\") + convB3\n",
    "    h3_batched = tf.layers.batch_normalization(a3, center=True, scale=True, training=is_training)\n",
    "    h3 = tf.nn.elu(h3_batched)\n",
    "    h3_pooled = tf.nn.max_pool(h3, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "    \n",
    "    a4 = tf.nn.conv2d(h3_pooled, convW4, strides=[1,1,1,1], padding=\"SAME\") + convB4\n",
    "    h4_batched = tf.layers.batch_normalization(a4, center=True, scale=True, training=is_training)\n",
    "    h4 = tf.nn.elu(h4_batched)\n",
    "    h4_pooled = tf.nn.max_pool(h4, [1,2,2,1], [1,2,2,1], padding=\"VALID\")\n",
    "            \n",
    "    a5 = tf.nn.conv2d(h4_pooled, convW5, strides=[1,1,1,1], padding=\"VALID\") + convB5\n",
    "    \n",
    "    h5_batched = tf.layers.batch_normalization(a5, center=True, scale=True, training=is_training)\n",
    "    h5 = tf.nn.elu(h5_batched)\n",
    "    \n",
    "    output = tf.reshape(h5, (-1,3))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 130, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove old variables\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 130, 130, 3])\n",
    "Y_label = tf.placeholder(tf.int32, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_out = my_model(X, Y_label, is_training)\n",
    "# mean_loss = tf.reduce_mean(tf.losses.hinge_loss(tf.one_hot(Y_label, 3), logits=y_out))\n",
    "# optimizer = tf.train.RMSPropOptimizer(1e-2)\n",
    "# optimizer.minimize(mean_loss)\n",
    "\n",
    "\n",
    "# # batch normalization in tensorflow requires this extra dependency\n",
    "# extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "# with tf.control_dependencies(extra_update_ops):\n",
    "#     train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     print('Training')\n",
    "#     run_model(sess, y_out, mean_loss, X_crop_train, Y_train_label ,10, 64, 100,train_step, True)\n",
    "#     print('Validation')\n",
    "#     run_model(sess, y_out, mean_loss, X_crop_val, Y_val_label , 1 , 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tensorflow / Keras, Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.99789544, -0.99786669, -0.99809666],\n",
       "        [-0.99789512, -0.99786436, -0.99811042],\n",
       "        [-0.99817462, -0.99814386, -0.99838992],\n",
       "        ...,\n",
       "        [-0.99569396, -0.99554018, -0.99572472],\n",
       "        [-0.99568793, -0.99553414, -0.99571869],\n",
       "        [-0.99594677, -0.99580303, -0.99597551]],\n",
       "\n",
       "       [[-0.99886452, -0.99883577, -0.99906574],\n",
       "        [-0.99888731, -0.99885655, -0.99910261],\n",
       "        [-0.99904204, -0.99901128, -0.99925734],\n",
       "        ...,\n",
       "        [-0.99569222, -0.99553844, -0.99572298],\n",
       "        [-0.99568261, -0.99552882, -0.99571336],\n",
       "        [-0.99594179, -0.99579806, -0.99597054]],\n",
       "\n",
       "       [[-0.99946598, -0.99943724, -0.99966721],\n",
       "        [-0.99942862, -0.99939786, -0.99964392],\n",
       "        [-0.99939916, -0.9993684 , -0.99961446],\n",
       "        ...,\n",
       "        [-0.99568391, -0.99553012, -0.99571467],\n",
       "        [-0.99565891, -0.99550513, -0.99568967],\n",
       "        [-0.99592631, -0.99578258, -0.99595506]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.99638625, -0.99618503, -0.99664497],\n",
       "        [-0.99618669, -0.99597139, -0.99646351],\n",
       "        [-0.996513  , -0.9962977 , -0.99678982],\n",
       "        ...,\n",
       "        [-0.9996764 , -0.99958413, -0.99979943],\n",
       "        [-0.99966167, -0.9995694 , -0.9997847 ],\n",
       "        [-0.99968379, -0.99959755, -0.99979878]],\n",
       "\n",
       "       [[-0.99690092, -0.9966997 , -0.99715964],\n",
       "        [-0.99674973, -0.99653443, -0.99702655],\n",
       "        [-0.99704562, -0.99683032, -0.99732243],\n",
       "        ...,\n",
       "        [-0.99966525, -0.99957298, -0.99978828],\n",
       "        [-0.99966167, -0.9995694 , -0.9997847 ],\n",
       "        [-0.99968379, -0.99959755, -0.99979878]],\n",
       "\n",
       "       [[-0.99760631, -0.99740509, -0.99786503],\n",
       "        [-0.99741984, -0.99720453, -0.99769665],\n",
       "        [-0.99758678, -0.99737148, -0.9978636 ],\n",
       "        ...,\n",
       "        [-0.99966167, -0.9995694 , -0.9997847 ],\n",
       "        [-0.99966167, -0.9995694 , -0.9997847 ],\n",
       "        [-0.99968379, -0.99959755, -0.99979878]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_crop_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageInput = tf.keras.Input(shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(input_tensor=imageInput, include_top=False, weights=\"imagenet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_layer = model.get_layer('block5_pool').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten = tf.keras.layers.Flatten()(last_layer)\n",
    "out = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_vgg_model = tf.keras.Model(imageInput, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 14,716,227\n",
      "Trainable params: 14,716,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "custom_vgg_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 14,716,227\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.7141 - acc: 0.5740 - val_loss: 0.6676 - val_acc: 0.5000\n",
      "Epoch 2/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6371 - acc: 0.6640 - val_loss: 0.6158 - val_acc: 0.9000\n",
      "Epoch 3/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.6042 - acc: 0.8000 - val_loss: 0.5785 - val_acc: 0.9160\n",
      "Epoch 4/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5710 - acc: 0.9010 - val_loss: 0.5526 - val_acc: 0.9340\n",
      "Epoch 5/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5490 - acc: 0.8860 - val_loss: 0.5229 - val_acc: 0.9480\n",
      "Epoch 6/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.5146 - acc: 0.9230 - val_loss: 0.5135 - val_acc: 0.8540\n",
      "Epoch 7/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4946 - acc: 0.9330 - val_loss: 0.4738 - val_acc: 0.9580\n",
      "Epoch 8/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4726 - acc: 0.9410 - val_loss: 0.4527 - val_acc: 0.9620\n",
      "Epoch 9/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4571 - acc: 0.9130 - val_loss: 0.4313 - val_acc: 0.9400\n",
      "Epoch 10/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4396 - acc: 0.9340 - val_loss: 0.4159 - val_acc: 0.9180\n",
      "Epoch 11/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4207 - acc: 0.9310 - val_loss: 0.3979 - val_acc: 0.9420\n",
      "Epoch 12/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.4050 - acc: 0.9470 - val_loss: 0.3976 - val_acc: 0.9000\n",
      "Epoch 13/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3937 - acc: 0.9290 - val_loss: 0.3726 - val_acc: 0.9220\n",
      "Epoch 14/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3808 - acc: 0.9370 - val_loss: 0.3630 - val_acc: 0.9200\n",
      "Epoch 15/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3667 - acc: 0.9410 - val_loss: 0.3466 - val_acc: 0.9560\n",
      "Epoch 16/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3544 - acc: 0.9480 - val_loss: 0.3475 - val_acc: 0.942043 - acc:\n",
      "Epoch 17/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3463 - acc: 0.9490 - val_loss: 0.3272 - val_acc: 0.9580\n",
      "Epoch 18/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3338 - acc: 0.9460 - val_loss: 0.3204 - val_acc: 0.9620\n",
      "Epoch 19/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3273 - acc: 0.9500 - val_loss: 0.3076 - val_acc: 0.9520\n",
      "Epoch 20/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3222 - acc: 0.9430 - val_loss: 0.3124 - val_acc: 0.9140\n",
      "Epoch 21/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3115 - acc: 0.9430 - val_loss: 0.2944 - val_acc: 0.9540\n",
      "Epoch 22/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3046 - acc: 0.9530 - val_loss: 0.2848 - val_acc: 0.9520\n",
      "Epoch 23/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2951 - acc: 0.9460 - val_loss: 0.2786 - val_acc: 0.9560\n",
      "Epoch 24/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2915 - acc: 0.9480 - val_loss: 0.2719 - val_acc: 0.9520\n",
      "Epoch 25/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2865 - acc: 0.9460 - val_loss: 0.2673 - val_acc: 0.9420\n",
      "Epoch 26/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2848 - acc: 0.9370 - val_loss: 0.2617 - val_acc: 0.9580\n",
      "Epoch 27/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2716 - acc: 0.9520 - val_loss: 0.2560 - val_acc: 0.9460\n",
      "Epoch 28/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2666 - acc: 0.9450 - val_loss: 0.2529 - val_acc: 0.9560\n",
      "Epoch 29/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2649 - acc: 0.9460 - val_loss: 0.2481 - val_acc: 0.9560\n",
      "Epoch 30/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2580 - acc: 0.9480 - val_loss: 0.2414 - val_acc: 0.9560\n",
      "Epoch 31/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2611 - acc: 0.9440 - val_loss: 0.2379 - val_acc: 0.9580\n",
      "Epoch 32/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2491 - acc: 0.9560 - val_loss: 0.2347 - val_acc: 0.9580\n",
      "Epoch 33/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2451 - acc: 0.9490 - val_loss: 0.2290 - val_acc: 0.9560\n",
      "Epoch 34/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2404 - acc: 0.9490 - val_loss: 0.2258 - val_acc: 0.9500\n",
      "Epoch 35/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2371 - acc: 0.9490 - val_loss: 0.2304 - val_acc: 0.9580\n",
      "Epoch 36/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2339 - acc: 0.9510 - val_loss: 0.2186 - val_acc: 0.9560\n",
      "Epoch 37/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2326 - acc: 0.9520 - val_loss: 0.2174 - val_acc: 0.9600A: 0s - loss: 0.2269 - a\n",
      "Epoch 38/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2326 - acc: 0.9460 - val_loss: 0.2122 - val_acc: 0.9580\n",
      "Epoch 39/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2237 - acc: 0.9540 - val_loss: 0.2111 - val_acc: 0.9580\n",
      "Epoch 40/40\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.2211 - acc: 0.9520 - val_loss: 0.2066 - val_acc: 0.9540\n",
      "500/500 [==============================] - 1s 2ms/step\n",
      "Test Loss:  0.21986567950248717\n",
      "Test Accu: 0.9539999995231628\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    train_y = np.zeros((len(Y_train_label), num_classes))\n",
    "    val_y = np.zeros((len(Y_val_label), num_classes))\n",
    "    test_y = np.zeros((len(Y_test_label), num_classes))\n",
    "    \n",
    "    train_y[np.arange(len(Y_train_label)), Y_train_label] = 1\n",
    "    val_y[np.arange(len(Y_val_label)), Y_val_label] = 1\n",
    "    test_y[np.arange(len(Y_test_label)), Y_test_label] = 1\n",
    "    \n",
    "    \n",
    "    test1 = tf.keras.applications.vgg16.preprocess_input(X_crop_train)\n",
    "    test2 = tf.keras.applications.vgg16.preprocess_input(X_crop_val)\n",
    "    test3 = tf.keras.applications.vgg16.preprocess_input(X_crop_test)\n",
    "    \n",
    "    custom_vgg_model.fit(test1, train_y, batch_size=32,epochs=40, \n",
    "                         verbose=1, validation_data=(test2, val_y ))\n",
    "    \n",
    "    score = custom_vgg_model.evaluate(test3, test_y)\n",
    "    print(\"Test Loss: \", score[0])\n",
    "    print(\"Test Accu:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg19InputImage = tf.keras.Input(shape=(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg19_model = tf.keras.applications.VGG19(input_tensor=vgg19InputImage,\n",
    "                                                include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg19_last = vgg19_model.get_layer(\"block5_pool\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg19_flatten = tf.keras.layers.Flatten(name=\"vgg19_flatten\")(vgg19_last)\n",
    "vgg19_output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(vgg19_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_vgg19_model = tf.keras.Model(vgg19InputImage, vgg19_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "vgg19_flatten (Flatten)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 20,025,923\n",
      "Trainable params: 20,025,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in custom_vgg19_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "custom_vgg19_model.compile(loss=\"categorical_hinge\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "vgg19_flatten (Flatten)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 20,025,923\n",
      "Trainable params: 1,539\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.9986 - acc: 0.5510 - val_loss: 0.9961 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9953 - acc: 0.4970 - val_loss: 0.9921 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9922 - acc: 0.4900 - val_loss: 0.9878 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9885 - acc: 0.4900 - val_loss: 0.9835 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9845 - acc: 0.4900 - val_loss: 0.9784 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9801 - acc: 0.4900 - val_loss: 0.9737 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9758 - acc: 0.4900 - val_loss: 0.9686 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9705 - acc: 0.4900 - val_loss: 0.9623 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9662 - acc: 0.4900 - val_loss: 0.9572 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9612 - acc: 0.4900 - val_loss: 0.9517 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9559 - acc: 0.4900 - val_loss: 0.9463 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9511 - acc: 0.4900 - val_loss: 0.9418 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9461 - acc: 0.4920 - val_loss: 0.9363 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9412 - acc: 0.4930 - val_loss: 0.9311 - val_acc: 0.5020\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9365 - acc: 0.5020 - val_loss: 0.9263 - val_acc: 0.5340\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9315 - acc: 0.5390 - val_loss: 0.9211 - val_acc: 0.5580\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9268 - acc: 0.6890 - val_loss: 0.9161 - val_acc: 0.6800\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9220 - acc: 0.5570 - val_loss: 0.9111 - val_acc: 0.7560\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9179 - acc: 0.8910 - val_loss: 0.9066 - val_acc: 0.9140\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9125 - acc: 0.8650 - val_loss: 0.9010 - val_acc: 0.8080\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9076 - acc: 0.8120 - val_loss: 0.8962 - val_acc: 0.8540\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.9029 - acc: 0.9130 - val_loss: 0.8925 - val_acc: 0.9500\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8977 - acc: 0.9170 - val_loss: 0.8868 - val_acc: 0.9220\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8936 - acc: 0.9000 - val_loss: 0.8826 - val_acc: 0.9440\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8892 - acc: 0.9210 - val_loss: 0.8773 - val_acc: 0.9280\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8844 - acc: 0.9350 - val_loss: 0.8735 - val_acc: 0.9540\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8800 - acc: 0.9190 - val_loss: 0.8683 - val_acc: 0.9440\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8754 - acc: 0.9280 - val_loss: 0.8638 - val_acc: 0.9540\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8713 - acc: 0.9340 - val_loss: 0.8597 - val_acc: 0.9580\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8667 - acc: 0.9320 - val_loss: 0.8544 - val_acc: 0.9480\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8624 - acc: 0.9390 - val_loss: 0.8508 - val_acc: 0.9580\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8587 - acc: 0.9360 - val_loss: 0.8460 - val_acc: 0.9580\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8546 - acc: 0.9330 - val_loss: 0.8415 - val_acc: 0.9580\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8498 - acc: 0.9420 - val_loss: 0.8369 - val_acc: 0.9540\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8454 - acc: 0.9430 - val_loss: 0.8323 - val_acc: 0.9520\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8414 - acc: 0.9340 - val_loss: 0.8277 - val_acc: 0.9540\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8373 - acc: 0.9370 - val_loss: 0.8241 - val_acc: 0.9580\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8331 - acc: 0.9380 - val_loss: 0.8197 - val_acc: 0.9580\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8288 - acc: 0.9420 - val_loss: 0.8151 - val_acc: 0.9580\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8250 - acc: 0.9430 - val_loss: 0.8105 - val_acc: 0.9520\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8206 - acc: 0.9330 - val_loss: 0.8060 - val_acc: 0.9540\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8168 - acc: 0.9380 - val_loss: 0.8025 - val_acc: 0.9600\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8134 - acc: 0.9370 - val_loss: 0.7977 - val_acc: 0.9540\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8093 - acc: 0.9330 - val_loss: 0.7935 - val_acc: 0.9580\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8049 - acc: 0.9420 - val_loss: 0.7891 - val_acc: 0.9540\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.8010 - acc: 0.9460 - val_loss: 0.7854 - val_acc: 0.9560\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7972 - acc: 0.9430 - val_loss: 0.7810 - val_acc: 0.9540\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7944 - acc: 0.9370 - val_loss: 0.7773 - val_acc: 0.9560\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7890 - acc: 0.9420 - val_loss: 0.7731 - val_acc: 0.9560\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.7852 - acc: 0.9430 - val_loss: 0.7690 - val_acc: 0.9560\n",
      "500/500 [==============================] - 1s 2ms/step\n",
      "Test Loss:  0.7799973416328431\n",
      "Test Accu: 0.9459999990463257\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    train_y = np.zeros((len(Y_train_label), num_classes))\n",
    "    val_y = np.zeros((len(Y_val_label), num_classes))\n",
    "    test_y = np.zeros((len(Y_test_label), num_classes))\n",
    "    \n",
    "    train_y[np.arange(len(Y_train_label)), Y_train_label] = 1\n",
    "    val_y[np.arange(len(Y_val_label)), Y_val_label] = 1\n",
    "    test_y[np.arange(len(Y_test_label)), Y_test_label] = 1\n",
    "    \n",
    "    test1 = tf.keras.applications.vgg19.preprocess_input(X_crop_train)\n",
    "    test2 = tf.keras.applications.vgg19.preprocess_input(X_crop_val)\n",
    "    test3 = tf.keras.applications.vgg19.preprocess_input(X_crop_test)\n",
    "\n",
    "    custom_vgg19_model.fit(test1, train_y, batch_size=20,epochs=50, \n",
    "                         verbose=1, validation_data=(test2, val_y ))\n",
    "    \n",
    "    score = custom_vgg19_model.evaluate(test3, test_y)\n",
    "    print(\"Test Loss: \", score[0])\n",
    "    print(\"Test Accu:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
